
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

    <title>Forecaster Class &#8212; scalecast 0.5.6 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/haiku.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <link rel="shortcut icon" href="../_static/logo2.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Forecaster Object Globals" href="ForecasterGlobals.html" />
    <link rel="prev" title="LSTM Example" href="examples/LSTM.html" /> 
  </head><body>
      <div class="header" role="banner">
        <a href="../index.html">
          <img class="logo" src="../_static/logo2.png" alt="Logo"/>
        </a>
      </div>
      <div class="topnav" role="navigation" aria-label="top navigation">
      
        <p>
        «&#160;&#160;<a href="examples/LSTM.html">LSTM Example</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="../index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="ForecasterGlobals.html">Forecaster Object Globals</a>&#160;&#160;»
        </p>

      </div>
      <div class="content" role="main">
        
        
  <section id="forecaster-class">
<h1>Forecaster Class<a class="headerlink" href="#forecaster-class" title="Permalink to this headline">¶</a></h1>
<p>This is the main object that is utilized for data differencing, adding regressors to predict with, adding lagged values of y, and saving, visualizing, and exporting results.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scalecast.Forecaster</span> <span class="kn">import</span> <span class="n">Forecaster</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">array_of_dates</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;2021-01-01&#39;</span><span class="p">,</span><span class="s1">&#39;2021-01-02&#39;</span><span class="p">,</span><span class="s1">&#39;2021-01-03&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">array_of_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">Forecaster</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">array_of_values</span><span class="p">,</span> <span class="n">current_dates</span><span class="o">=</span><span class="n">array_of_dates</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py class">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">scalecast.Forecaster.</span></span><span class="sig-name descname"><span class="pre">Forecaster</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_dates</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_AR_terms" title="scalecast.Forecaster.Forecaster.add_AR_terms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_AR_terms</span></code></a>(N)</p></td>
<td><p>add seasonal AR terms N: tuple of len 2 (P,m)     P: int         the number of terms to add     m: int         the seasonal period (12 for monthly data, etc.)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_ar_terms" title="scalecast.Forecaster.Forecaster.add_ar_terms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_ar_terms</span></code></a>(n)</p></td>
<td><p>add auto-regressive terms to forecast with n: int     the number of terms to add (1 to this number will be added)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_combo_regressors" title="scalecast.Forecaster.Forecaster.add_combo_regressors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_combo_regressors</span></code></a>(*args[, sep])</p></td>
<td><p>combines all passed variables by multiplying their values together <a href="#id1"><span class="problematic" id="id2">*</span></a>args: names of Xvars that aleady exist in the object sep: str, default ‘_’     the separator between each term in arg to create the final variable name</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_covid19_regressor" title="scalecast.Forecaster.Forecaster.add_covid19_regressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_covid19_regressor</span></code></a>([called, start, end])</p></td>
<td><p>adds dummy variable that is 1 during the time period that covid19 effects are present for the series, 0 otherwise</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_diffed_terms" title="scalecast.Forecaster.Forecaster.add_diffed_terms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_diffed_terms</span></code></a>(*args[, diff, sep])</p></td>
<td><p>differences all passed variables (no AR terms) up to 2 times <a href="#id3"><span class="problematic" id="id4">*</span></a>args: names of Xvars that aleady exist in the object diff: one of {1,2}, default 1     the number of times to difference each variable passed to args sep: str, default ‘_’     the separator between each term in arg to create the final variable name     resulting variable names will be like “tdiff_1” or “tdiff_2” by default</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_exp_terms" title="scalecast.Forecaster.Forecaster.add_exp_terms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_exp_terms</span></code></a>(*args, pwr[, sep, cutoff])</p></td>
<td><p>raises all passed variables (no AR terms) to exponential powers (ints or floats) <a href="#id5"><span class="problematic" id="id6">*</span></a>args: names of Xvars that aleady exist in the object pwr: float     the power to raise each term to in args     can use values like 0.5 to perform square roots, etc. sep: str, default ‘^’     the separator between each term in arg to create the final variable name cutoff: int, default 2     the resulting variable name will be rounded to this number based on the passed pwr     for instance, if pwr = 0.33333333333 and ‘t’ is passed as an arg to <a href="#id7"><span class="problematic" id="id8">*</span></a>args, the resulting name will be t^0.33 by default.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_lagged_terms" title="scalecast.Forecaster.Forecaster.add_lagged_terms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_lagged_terms</span></code></a>(*args[, lags, upto, sep])</p></td>
<td><p>lags all passed variables (no AR terms) 1 or more times <a href="#id9"><span class="problematic" id="id10">*</span></a>args: names of Xvars that aleady exist in the object lags: int greater than 0, default 1     the number of times to lag each passed variable upto: bool, default True     whether to add all lags up to the number passed to lags     if you pass 6 to lags and upto is True, lags 1, 2, 3, 4, 5, 6 will all be added     if you pass 6 to lags and upto is False, lag 6 only will be added sep: str, default ‘_’     the separator between each term in arg to create the final variable name     resulting variable names will be like “tlag_1” or “tlag_2” by default</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_logged_terms" title="scalecast.Forecaster.Forecaster.add_logged_terms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_logged_terms</span></code></a>(*args[, base, sep])</p></td>
<td><p>logs all passed variables (no AR terms) <a href="#id11"><span class="problematic" id="id12">*</span></a>args: names of Xvars that aleady exist in the object base: math.e or int greater than 1     the log base sep: str, default ‘’     the separator between each term in arg to create the final variable name     resulting variable names will be like “log2t” or “lnt” by default</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_other_regressor" title="scalecast.Forecaster.Forecaster.add_other_regressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_other_regressor</span></code></a>(called, start, end)</p></td>
<td><p>adds dummy variable that is 1 during the specified time period, 0 otherwise called: str     what to call the resulting variable start: str, datetime, or pd.Timestamp object end: str, datetime, or pd.Timestamp object</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_poly_terms" title="scalecast.Forecaster.Forecaster.add_poly_terms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_poly_terms</span></code></a>(*args[, pwr, sep])</p></td>
<td><p>raises all passed variables (no AR terms) to exponential powers (ints only) <a href="#id13"><span class="problematic" id="id14">*</span></a>args: names of Xvars that aleady exist in the object pwr: int, default 2     the max power to add to each term in args (2 to this number will be added) sep: str, default ‘^’     the separator between each term in arg to create the final variable name</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_pt_terms" title="scalecast.Forecaster.Forecaster.add_pt_terms"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_pt_terms</span></code></a>(*args[, method, sep])</p></td>
<td><p>applies a box-cox or yeo-johnson power transformation to all passed variables (no AR terms) <a href="#id15"><span class="problematic" id="id16">*</span></a>args: names of Xvars that aleady exist in the object method: one of {‘box-cox’,’yeo-johnson’}, default ‘box-cox’     the type of transformation     box-cox works for positive values only     yeo-johnson is like a box-cox but can be used with 0s or negatives (<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html</a>) sep: str, default ‘’     the separator between each term in arg to create the final variable name     resulting variable names will be like “box-cox_t” or “yeo-johnson_t” by default</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_seasonal_regressors" title="scalecast.Forecaster.Forecaster.add_seasonal_regressors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_seasonal_regressors</span></code></a>(*args[, raw, …])</p></td>
<td><p>adds seasonal regressors to the object <a href="#id17"><span class="problematic" id="id18">*</span></a>args: each of str type     values that return a series of int type from pandas.dt and pandas.dt.isocalendar() raw: bool, default True     whether to use the raw integer values sincos: bool, default False     whether to use a sin/cos transformation of the raw integer values (estimates the cycle based on the max observed value) dummy: bool, default False     whether to use dummy variables from the raw int values drop_first: bool, default False     whether to drop the first observed dummy level (saves a degree of freedom when model estimates an intercept)     not relevant when dummy = False</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.add_time_trend" title="scalecast.Forecaster.Forecaster.add_time_trend"><code class="xref py py-obj docutils literal notranslate"><span class="pre">add_time_trend</span></code></a>([called])</p></td>
<td><p>adds a time trend from 0 to len(current_dates) + len(future_dates) called: str, default ‘t’     what to call the resulting variable</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.adf_test" title="scalecast.Forecaster.Forecaster.adf_test"><code class="xref py py-obj docutils literal notranslate"><span class="pre">adf_test</span></code></a>([critical_pval, quiet, full_res, …])</p></td>
<td><p>tests the stationarity of the y series using augmented dickey fuller critical_pval: float, default 0.05     the p-value threshold in the statistical test to accept the alternative hypothesis quiet: bool, default True     if False, prints whether the tests suggests stationary or non-stationary data full_res: bool, default False     if True, returns a dictionary with the pvalue, evaluated statistic, and other statistical information (returns what the adfuller() function from statsmodels does)     if False, returns a bool that matches whether the test indicates stationarity train_only: bool, default False     if True, will exclude the test set from the test (a measure added to avoid leakage) <a href="#id19"><span class="problematic" id="id20">**</span></a>kwargs passed to adfuller() function from statsmodels</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.all_feature_info_to_excel" title="scalecast.Forecaster.Forecaster.all_feature_info_to_excel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">all_feature_info_to_excel</span></code></a>([out_path, excel_name])</p></td>
<td><p>saves all feature importance and summary stats to excel each model where such info is available for gets its own tab be sure to call save_summary_stats() and save_feature_importance() before using this function out_path: str, default ‘./’     the path to export to excel_name: str, default ‘feature_info.xlsx’     the name of the resulting excel file</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.all_validation_grids_to_excel" title="scalecast.Forecaster.Forecaster.all_validation_grids_to_excel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">all_validation_grids_to_excel</span></code></a>([out_path, …])</p></td>
<td><p>saves all validation grids to excel each model where such info is available for gets its own tab out_path: str, default ‘./’     the path to export to excel_name: str, default ‘feature_info.xlsx’     the name of the resulting excel file sort_by_metric_value: bool, default False ascending: bool, default True     whether to sort least-to-greatest     ignored if sort_by_metric_value is False</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.auto_forecast" title="scalecast.Forecaster.Forecaster.auto_forecast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">auto_forecast</span></code></a>([call_me, dynamic_testing])</p></td>
<td><p>auto forecast with the best parameters indicated from the tuning process see manual_forecast() docstring</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.diff" title="scalecast.Forecaster.Forecaster.diff"><code class="xref py py-obj docutils literal notranslate"><span class="pre">diff</span></code></a>([i])</p></td>
<td><p>differences the y attribute, as well as all regressor values stored in current_xreg and future_xreg call this after adding all desired ar terms and those terms will be differenced too if you add ar terms after differencing, an error will be raised i: one of {0,1,2}, default 1     the number of differences to take</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.drop_Xvars" title="scalecast.Forecaster.Forecaster.drop_Xvars"><code class="xref py py-obj docutils literal notranslate"><span class="pre">drop_Xvars</span></code></a>(*args)</p></td>
<td><p>drops regressors <a href="#id21"><span class="problematic" id="id22">*</span></a>args are names of regressors to drop</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.drop_regressors" title="scalecast.Forecaster.Forecaster.drop_regressors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">drop_regressors</span></code></a>(*args)</p></td>
<td><p>drops regressors <a href="#id23"><span class="problematic" id="id24">*</span></a>args are names of regressors to drop</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.export" title="scalecast.Forecaster.Forecaster.export"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export</span></code></a>([dfs, models, best_model, …])</p></td>
<td><p>exports 1-all of 5 pandas dataframes, can write to excel with each dataframe on a separate sheet will return either a dictionary with dataframes as values (df str arguments as keys) or a single dataframe if only one df is specified dfs: list-like or str, default [‘all_fcsts’,’model_summaries’,’best_fcst’,’test_set_predictions’,’lvl_fcsts’]     a list or name of the specific dataframe(s) you want returned and/or written to excel     must be one of or multiple of default models: list-like or str, default ‘all’     the models to write information for     can start with “<a href="#id77"><span class="problematic" id="id78">top_</span></a>” and the metric specified in <cite>determine_best_by</cite> will be used to order the models appropriately best_model: str, default ‘auto’     the name of the best model, if “auto”, will determine this by the metric in determine_best_by     if not “auto”, must match a model nickname of an already-evaluated model determine_best_by: one of _determine_best_by_, default ‘TestSetRMSE’ to_excel: bool, default False     whether to save to excel out_path: str, default ‘./’     the path to save the excel file to (ignored when <cite>to_excel=False</cite>) excel_name: str, default ‘results.xlsx’     the name to call the excel file (ignored when <cite>to_excel=False</cite>)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.export_Xvars_df" title="scalecast.Forecaster.Forecaster.export_Xvars_df"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export_Xvars_df</span></code></a>([dropna])</p></td>
<td><p>returns a pandas dataframe with all utilized regressors and values dropna: bool, default False     whether to drop null values from the resulting dataframe</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.export_feature_importance" title="scalecast.Forecaster.Forecaster.export_feature_importance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export_feature_importance</span></code></a>(model)</p></td>
<td><p>exports the feature importance from a model raises an error if you never saved the model’s feature importance model: str     the name of them model to export for, matches what was passed to call_me when calling the forecast (default is estimator name)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.export_fitted_vals" title="scalecast.Forecaster.Forecaster.export_fitted_vals"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export_fitted_vals</span></code></a>(model)</p></td>
<td><p>exports a single dataframe with fitted values and actuals model: str     the model nickname (must exist in history.keys())</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.export_forecasts_with_cis" title="scalecast.Forecaster.Forecaster.export_forecasts_with_cis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export_forecasts_with_cis</span></code></a>(model)</p></td>
<td><p>exports a single dataframe with forecasts and upper and lower forecast bounds model: str     the model nickname (must exist in history.keys())</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.export_summary_stats" title="scalecast.Forecaster.Forecaster.export_summary_stats"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export_summary_stats</span></code></a>(model)</p></td>
<td><p>exports the summary stats from a model raises an error if you never saved the model’s summary stats model: str     the name of them model to export for, matches what was passed to call_me when calling the forecast (default is estimator name)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.export_test_set_preds_with_cis" title="scalecast.Forecaster.Forecaster.export_test_set_preds_with_cis"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export_test_set_preds_with_cis</span></code></a>(model)</p></td>
<td><p>exports a single dataframe with test-set predictions, actuals, and upper and lower prediction bounds model: str     the model nickname (must exist in history.keys())</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.export_validation_grid" title="scalecast.Forecaster.Forecaster.export_validation_grid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">export_validation_grid</span></code></a>(model)</p></td>
<td><p>exports the validation from a model raises an error if you never tuned the model model: str     the name of them model to export for, matches what was passed to call_me when calling the forecast (default is estimator name)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.fillna_y" title="scalecast.Forecaster.Forecaster.fillna_y"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fillna_y</span></code></a>([how])</p></td>
<td><p>fills null values in the y attribute how: {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, ‘midpoint’}     midpoint is unique to this library and only works if there is not more than two missing values sequentially     all other possible arguments are from pandas.DataFrame.fillna() method and will do the same</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.generate_future_dates" title="scalecast.Forecaster.Forecaster.generate_future_dates"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate_future_dates</span></code></a>(n)</p></td>
<td><p>generates a certain amount of future dates based on an inferred frequency n: int     number of future dates to produce     this will also be the forecast length</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.get_freq" title="scalecast.Forecaster.Forecaster.get_freq"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_freq</span></code></a>()</p></td>
<td><p>returns the pandas inferred date frequency</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.get_funcs" title="scalecast.Forecaster.Forecaster.get_funcs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_funcs</span></code></a>(which)</p></td>
<td><p>returns a group of functions based on what’s passed to which which: str, one of {‘adder’,’exporter’,’setter’,’plotter’,’getter’}</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.get_regressor_names" title="scalecast.Forecaster.Forecaster.get_regressor_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_regressor_names</span></code></a>()</p></td>
<td><p>returns a lit of regressor names stored in the object</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.infer_freq" title="scalecast.Forecaster.Forecaster.infer_freq"><code class="xref py py-obj docutils literal notranslate"><span class="pre">infer_freq</span></code></a>()</p></td>
<td><p>uses pandas library to infer frequency of loaded dates</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.ingest_Xvars_df" title="scalecast.Forecaster.Forecaster.ingest_Xvars_df"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ingest_Xvars_df</span></code></a>(df[, date_col, drop_first, …])</p></td>
<td><p>ingest a dataframe of regressors with names (don’t start anything with AR!!!) all non-numeric values will be dummied df: pandas.DataFrame date_col: str, default ‘Date’     the name of the date column in the dataframe (use named index only if passing this column as an index) drop_first: bool, default False     whether to drop the first observation of any dummied variables, irrelevant if passing all numeric values use_future_dates: bool, default False     whether to use the future dates in the dataframe as the future_dates attribute in the object     if False, the dataframe must have at least the same number of observations as len(future_dates)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.ingest_grid" title="scalecast.Forecaster.Forecaster.ingest_grid"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ingest_grid</span></code></a>(grid)</p></td>
<td><p>ingests a grid to tune the estimator grid: dict or str     if dict, must be a user-created grid     if str, must match the name of a dict grid stored in Grids.py</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.integrate" title="scalecast.Forecaster.Forecaster.integrate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">integrate</span></code></a>([critical_pval, train_only, …])</p></td>
<td><p>differences the series 0, 1, or 2 times based on ADF test critical_pval: float, default 0.05     the p-value threshold in the statistical test to accept the alternative hypothesis train_only: bool, default False     if True, will exclude the test set from the test (a measure added to avoid leakage) max_integration: int, one of {1,2}, default 2     if 1, will only difference data up to one time even if the results of the test indicate two integrations     if 2, behaves how you would expect</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.keep_smaller_history" title="scalecast.Forecaster.Forecaster.keep_smaller_history"><code class="xref py py-obj docutils literal notranslate"><span class="pre">keep_smaller_history</span></code></a>(n)</p></td>
<td><p>cuts the amount of observations in the object (trims the current_dates and current_xreg attributes as well) n: int, str in ‘%Y-%m-%d’ format, or datetime object     if int, the number of observations to keep     otherwise, the last observation to keep</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.limit_grid_size" title="scalecast.Forecaster.Forecaster.limit_grid_size"><code class="xref py py-obj docutils literal notranslate"><span class="pre">limit_grid_size</span></code></a>(n[, random_seed])</p></td>
<td><p>makes a grid smaller randomly n: int or float     if int, randomly selects that many parameter combinations     if float, must be less than 1 and greater 0, randomly selects that percentage of parameter combinations random_seed: int, optional     set a seed to make results consistent</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.manual_forecast" title="scalecast.Forecaster.Forecaster.manual_forecast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">manual_forecast</span></code></a>([call_me, dynamic_testing])</p></td>
<td><p>manually forecasts with the hyperparameters, Xvars, and normalizer selection passed as keywoords call_me: str, optional     what to call the model when storing it in the object’s history dictionary     if not specified, the model’s nickname will be assigned the estimator value (‘mlp’ will be ‘mlp’, etc.)     duplicated names will be overwritten with the most recently called model dynamic_testing: bool, default True     whether to dynamically test the forecast (meaning AR terms will be propogated with predicted values)     setting this to False means faster performance, but gives a less-good indication of how well the forecast will perform out x amount of periods     when False, test-set metrics effectively become an average of one-step forecasts <a href="#id25"><span class="problematic" id="id26">**</span></a>kwargs are passed to the _forecast_{estimator}() method and can include such parameters as Xvars, normalizer, cap, and floor, in addition to any given model’s specific hyperparameters <a href="#id27"><span class="problematic" id="id28">**</span></a>kwargs include for sklearn and lstm models:     normalizer: one of {_normalizer_}, default ‘minmax’         if not None, normalizer applied to training data only to not leak     Xvars: list where all elements are in current_xreg keys, ‘all’, or None         if None and Xvars are required, None becomes equivalent to ‘all’</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.order_fcsts" title="scalecast.Forecaster.Forecaster.order_fcsts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">order_fcsts</span></code></a>(models[, determine_best_by])</p></td>
<td><p>returns a list of estiamated forecasts from best-to-worst models: list-like     each element must match an element in _estimators_ (except “combo”, which cannot be tuned) determine_best_by: one of _determine_best_by_</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.plot" title="scalecast.Forecaster.Forecaster.plot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot</span></code></a>([models, order_by, level, print_attr, …])</p></td>
<td><p>plots all forecasts with the actuals, or just actuals if no forecasts available models: list-like, str, or None; default ‘all’    the forecated models to plot    can start with “<a href="#id79"><span class="problematic" id="id80">top_</span></a>” and the metric specified in order_by will be used to order the models appropriately    if None or models/order_by combo invalid, will plot only actual values order_by: one of _determine_best_by_, default None level: bool, default False     if True, will always plot level forecasts     if False, will plot the forecasts at whatever level they were called on     if False and there are a mix of models passed with different integrations, will default to True print_attr: list-like, default []     attributes from history dict to print to console     if the attribute doesn’t exist for a passed model, will not raise error, will just skip that element to_png: bool, default False     whether to save the resulting image to a png file out_path: str, default ‘./’     the path to save the png file to (ignored when <cite>to_png=False</cite>) png_name: str, default ‘./plot.png’     the name of the resulting png image (ignored when <cite>to_png=False</cite>) ci: bool, default False     whether to display the confidence intervals     default is 100 boostrapped samples and a 95% confidence interval     change defaults by calling <cite>set_cilevel()</cite> and <cite>set_bootstrapped_samples()</cite> before forecasting     ignored when level = False</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.plot_acf" title="scalecast.Forecaster.Forecaster.plot_acf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_acf</span></code></a>([diffy, train_only])</p></td>
<td><p>plots an autocorrelation function of the y values diffy: one of {True,False,0,1,2}, default False     whether to difference the data and how many times before passing the values to the function     If False or 0, does not difference     If True or 1, differences 1 time     If 2, differences 2 times train_only: bool, default False     if True, will exclude the test set from the test (a measure added to avoid leakage) <a href="#id29"><span class="problematic" id="id30">**</span></a>kwargs passed to plot_acf() function from statsmodels</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.plot_fitted" title="scalecast.Forecaster.Forecaster.plot_fitted"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_fitted</span></code></a>([models, order_by, to_png, …])</p></td>
<td><p>plots all fitted values with the actuals models: list-like or str, default ‘all’    the forecated models to plot    can start with “<a href="#id81"><span class="problematic" id="id82">top_</span></a>” and the metric specified in order_by will be used to order the models appropriately order_by: one of _determine_best_by_, default None to_png: bool, default False     whether to save the resulting image to a png file out_path: str, default ‘./’     the path to save the png file to (ignored when <cite>to_png=False</cite>) png_name: str, default ‘./plot.png’     the name of the resulting png image (ignored when <cite>to_png=False</cite>)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.plot_pacf" title="scalecast.Forecaster.Forecaster.plot_pacf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_pacf</span></code></a>([diffy, train_only])</p></td>
<td><p>plots a partial autocorrelation function of the y values diffy: one of {True,False,0,1,2}, default False     whether to difference the data and how many times before passing the values to the function     If False or 0, does not difference     If True or 1, differences 1 time     If 2, differences 2 times train_only: bool, default False     if True, will exclude the test set from the test (a measure added to avoid leakage) <a href="#id31"><span class="problematic" id="id32">**</span></a>kwargs passed to plot_pacf() function from statsmodels</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.plot_periodogram" title="scalecast.Forecaster.Forecaster.plot_periodogram"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_periodogram</span></code></a>([diffy, train_only])</p></td>
<td><p>plots a periodogram of the y values (comes from scipy.signal) diffy: one of {True,False,0,1,2}, default False     whether to difference the data and how many times before passing the values to the function     If False or 0, does not difference     If True or 1, differences 1 time     If 2, differences 2 times train_only: bool, default False     if True, will exclude the test set from the test (a measure added to avoid leakage)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.plot_test_set" title="scalecast.Forecaster.Forecaster.plot_test_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_test_set</span></code></a>([models, order_by, …])</p></td>
<td><p>plots all test-set predictions with the actuals models: list-like or str, default ‘all’    the forecated models to plot    can start with “<a href="#id83"><span class="problematic" id="id84">top_</span></a>” and the metric specified in order_by will be used to order the models appropriately order_by: one of _determine_best_by_, default None include_train: bool or int, default True     use to zoom into training results     if True, plots the test results with the entire history in y     if False, matches y history to test results and only plots this     if int, plots that length of y to match to test results level: bool, default False     if True, will always plot level forecasts     if False, will plot the forecasts at whatever level they were called on     if False and there are a mix of models passed with different integrations, will default to True to_png: bool, default False     whether to save the resulting image to a png file out_path: str, default ‘./’     the path to save the png file to (ignored when <cite>to_png=False</cite>) png_name: str, default ‘./plot.png’     the name of the resulting png image (ignored when <cite>to_png=False</cite>) ci: bool, default False     whether to display the confidence intervals     default is 100 boostrapped samples and a 95% confidence interval     change defaults by calling <cite>set_cilevel()</cite> and <cite>set_bootstrapped_samples()</cite> before forecasting     ignored when level = False</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.pop" title="scalecast.Forecaster.Forecaster.pop"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pop</span></code></a>(*args)</p></td>
<td><p>deletes evaluated forecasts from the history dictionary <a href="#id33"><span class="problematic" id="id34">*</span></a>args names of models matching what was passed to call_me (default for call_me in a given model is the same as the estimator name)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.pop_using_criterion" title="scalecast.Forecaster.Forecaster.pop_using_criterion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">pop_using_criterion</span></code></a>(metric, evaluated_as, …)</p></td>
<td><p>deletes all forecasts from history that meet a given criterion metric: str, one of _determine_best_by_ + [‘AnyPrediction’,’AnyLevelPrediction’] evaluated_as: str, one of {“&lt;”,”&lt;=”,”&gt;”,”&gt;=”,”==”} threshold: float delete_all: bool, default True     if the passed criterion deletes all forecasts, whether to actually delete all forecasts     if False and all forecasts meet criterion, will keep them all &gt;&gt;&gt; f.pop_using_criterion(‘LevelTestSetMAPE’,’&gt;’,2) &gt;&gt;&gt; f.pop_using_criterion(‘AnyPrediction’,’&lt;’,0,delete_all=False)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.reset" title="scalecast.Forecaster.Forecaster.reset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reset</span></code></a>()</p></td>
<td><p>drops all regressors and reverts object to original (level) state when initiated</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.save_feature_importance" title="scalecast.Forecaster.Forecaster.save_feature_importance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_feature_importance</span></code></a>()</p></td>
<td><p>save feature info for models that offer it will not raise errors if not available</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.save_summary_stats" title="scalecast.Forecaster.Forecaster.save_summary_stats"><code class="xref py py-obj docutils literal notranslate"><span class="pre">save_summary_stats</span></code></a>()</p></td>
<td><p>save summary stats for models that offer it will not raise errors if not available</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.seasonal_decompose" title="scalecast.Forecaster.Forecaster.seasonal_decompose"><code class="xref py py-obj docutils literal notranslate"><span class="pre">seasonal_decompose</span></code></a>([diffy, train_only])</p></td>
<td><p>plots a signal/seasonal decomposition of the y values diffy: one of {True,False,0,1,2}, default False     whether to difference the data and how many times before passing the values to the function     If False or 0, does not difference     If True or 1, differences 1 time     If 2, differences 2 times train_only: bool, default False     if True, will exclude the test set from the test (a measure added to avoid leakage) <a href="#id35"><span class="problematic" id="id36">**</span></a>kwargs passed to seasonal_decompose() function from statsmodels</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.set_bootstrap_samples" title="scalecast.Forecaster.Forecaster.set_bootstrap_samples"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_bootstrap_samples</span></code></a>(n)</p></td>
<td><p>sets the number of bootstrap samples to set confidence intervals for each model (default is 100) n: float greater than or equal to 30     30 because you need around there to satisfy central limit theorem     the lower this number, the faster the performance, but the less sure of the outcome you can be</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.set_cilevel" title="scalecast.Forecaster.Forecaster.set_cilevel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_cilevel</span></code></a>(n)</p></td>
<td><p>sets the level for the resulting confidence intervals (95% default) n: float greater than 0 and less than 1</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.set_estimator" title="scalecast.Forecaster.Forecaster.set_estimator"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_estimator</span></code></a>(estimator)</p></td>
<td><p>sets the estimator to forecast with estimator: one of _estimators_</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.set_last_future_date" title="scalecast.Forecaster.Forecaster.set_last_future_date"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_last_future_date</span></code></a>(date)</p></td>
<td><p>generates future dates that ends on the passed date date: datetime.datetime, pandas.Timestamp, or str (‘%Y-%m-%d’ format)     the date to end on     the number of future generated dates will be used as the forecast length</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.set_test_length" title="scalecast.Forecaster.Forecaster.set_test_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_test_length</span></code></a>([n])</p></td>
<td><p>set the length of the test set (no fractional splits) n: int, default 1     the length of the resulting test set</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.set_validation_length" title="scalecast.Forecaster.Forecaster.set_validation_length"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_validation_length</span></code></a>([n])</p></td>
<td><p>set the length of the validation set (no fractional splits) n: int, default 1     the length of the resulting validation set</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.set_validation_metric" title="scalecast.Forecaster.Forecaster.set_validation_metric"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_validation_metric</span></code></a>([metric])</p></td>
<td><p>sets the metric that will be used to tune all subsequent models not a good idea to change this if you are planning to combo model as weird things could happen metric: one of _metrics_, default ‘rmse’     the metric to optimize the models on using the validation set</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.tune" title="scalecast.Forecaster.Forecaster.tune"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tune</span></code></a>([dynamic_tuning])</p></td>
<td><p>tunes the specified estimator using an ingested grid (ingests a grid from Grids.py with same name as the estimator by default) any parameters you can pass as <a href="#id37"><span class="problematic" id="id38">**</span></a>kwargs to manual_forecast() can be tuned with this process dynamic_tuning: bool, default False     whether to dynamically tune the forecast (meaning AR terms will be propogated with predicted values)     setting this to False means faster performance, but gives a less-good indication of how well the forecast will perform out x amount of periods     when False, metrics effectively become an average of one-step forecasts</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.tune_test_forecast" title="scalecast.Forecaster.Forecaster.tune_test_forecast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tune_test_forecast</span></code></a>(models[, dynamic_tuning, …])</p></td>
<td><p>iterates through a list of models, tunes them using grids in Grids.py, forecasts them, and can save feature information models: list-like     each element must match an element in _estimators_ (except “combo”, which cannot be tuned) dynamic_tuning: bool, default False     whether to dynamically tune the forecast (meaning AR terms will be propogated with predicted values)     setting this to False means faster performance, but gives a less-good indication of how well the forecast will perform out x amount of periods     when False, metrics effectively become an average of one-step forecasts dynamic_testing: bool, default True     whether to dynamically test the forecast (meaning AR terms will be propogated with predicted values)     setting this to False means faster performance, but gives a less-good indication of how well the forecast will perform out x amount of periods     when False, test-set metrics effectively become an average of one-step forecasts summary_stats: bool, default False     whether to save summary stats for the models that offer those feature_importance: bool, default False     whether to save permutation feature importance information for the models that offer those</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.typ_set" title="scalecast.Forecaster.Forecaster.typ_set"><code class="xref py py-obj docutils literal notranslate"><span class="pre">typ_set</span></code></a>()</p></td>
<td><p>converts all objects in y, current_dates, future_dates, current_xreg, and future_xreg to appropriate types if possible</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.undiff" title="scalecast.Forecaster.Forecaster.undiff"><code class="xref py py-obj docutils literal notranslate"><span class="pre">undiff</span></code></a>([suppress_error])</p></td>
<td><p>undifferences y to original level and drops all regressors (such as AR terms) suppress_error: bool, default False     whether to suppress an error that gets raised if the series was never differenced</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#scalecast.Forecaster.Forecaster.validate_regressor_names" title="scalecast.Forecaster.Forecaster.validate_regressor_names"><code class="xref py py-obj docutils literal notranslate"><span class="pre">validate_regressor_names</span></code></a>()</p></td>
<td><p>validates that all regressor names exist in both current_xregs and future_xregs</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_AR_terms">
<span class="sig-name descname"><span class="pre">add_AR_terms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_AR_terms" title="Permalink to this definition">¶</a></dt>
<dd><p>add seasonal AR terms
N: tuple of len 2 (P,m)</p>
<blockquote>
<div><dl class="simple">
<dt>P: int</dt><dd><p>the number of terms to add</p>
</dd>
<dt>m: int</dt><dd><p>the seasonal period (12 for monthly data, etc.)</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_ar_terms">
<span class="sig-name descname"><span class="pre">add_ar_terms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_ar_terms" title="Permalink to this definition">¶</a></dt>
<dd><p>add auto-regressive terms to forecast with
n: int</p>
<blockquote>
<div><p>the number of terms to add (1 to this number will be added)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_combo_regressors">
<span class="sig-name descname"><span class="pre">add_combo_regressors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'_'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_combo_regressors" title="Permalink to this definition">¶</a></dt>
<dd><p>combines all passed variables by multiplying their values together
<a href="#id39"><span class="problematic" id="id40">*</span></a>args: names of Xvars that aleady exist in the object
sep: str, default ‘_’</p>
<blockquote>
<div><p>the separator between each term in arg to create the final variable name</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_covid19_regressor">
<span class="sig-name descname"><span class="pre">add_covid19_regressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">called</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'COVID19'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">datetime.datetime(2020,</span> <span class="pre">3,</span> <span class="pre">15,</span> <span class="pre">0,</span> <span class="pre">0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">datetime.datetime(2021,</span> <span class="pre">5,</span> <span class="pre">13,</span> <span class="pre">0,</span> <span class="pre">0)</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_covid19_regressor" title="Permalink to this definition">¶</a></dt>
<dd><dl>
<dt>adds dummy variable that is 1 during the time period that covid19 effects are present for the series, 0 otherwise</dt><dd><p>this function may be out of date as the pandemic has lasted longer than most expected, but we are keeping it for now
called str, default ‘COVID19’</p>
<blockquote>
<div><p>what to call the resulting variable</p>
</div></blockquote>
<dl class="simple">
<dt>start: str, datetime, or pd.Timestamp object, default datetime.datetime(2020,3,15)</dt><dd><p>the start date (default is day Walt Disney World closed in the U.S.)
use format yyyy-mm-dd when passing strings</p>
</dd>
</dl>
</dd>
<dt>end: str, datetime, or pd.Timestamp object, default datetime.datetime(2021,5,13)</dt><dd><dl class="simple">
<dt>the end date (default is day the U.S. CDC dropped mask mandate/recommendation for vaccinated people)</dt><dd><p>use format yyyy-mm-dd when passing strings</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_diffed_terms">
<span class="sig-name descname"><span class="pre">add_diffed_terms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'_'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_diffed_terms" title="Permalink to this definition">¶</a></dt>
<dd><p>differences all passed variables (no AR terms) up to 2 times
<a href="#id41"><span class="problematic" id="id42">*</span></a>args: names of Xvars that aleady exist in the object
diff: one of {1,2}, default 1</p>
<blockquote>
<div><p>the number of times to difference each variable passed to args</p>
</div></blockquote>
<dl class="simple">
<dt>sep: str, default ‘_’</dt><dd><p>the separator between each term in arg to create the final variable name
resulting variable names will be like “tdiff_1” or “tdiff_2” by default</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_exp_terms">
<span class="sig-name descname"><span class="pre">add_exp_terms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pwr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'^'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_exp_terms" title="Permalink to this definition">¶</a></dt>
<dd><p>raises all passed variables (no AR terms) to exponential powers (ints or floats)
<a href="#id43"><span class="problematic" id="id44">*</span></a>args: names of Xvars that aleady exist in the object
pwr: float</p>
<blockquote>
<div><p>the power to raise each term to in args
can use values like 0.5 to perform square roots, etc.</p>
</div></blockquote>
<dl class="simple">
<dt>sep: str, default ‘^’</dt><dd><p>the separator between each term in arg to create the final variable name</p>
</dd>
<dt>cutoff: int, default 2</dt><dd><p>the resulting variable name will be rounded to this number based on the passed pwr
for instance, if pwr = 0.33333333333 and ‘t’ is passed as an arg to <a href="#id45"><span class="problematic" id="id46">*</span></a>args, the resulting name will be t^0.33 by default</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_lagged_terms">
<span class="sig-name descname"><span class="pre">add_lagged_terms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lags</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">upto</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'_'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_lagged_terms" title="Permalink to this definition">¶</a></dt>
<dd><p>lags all passed variables (no AR terms) 1 or more times
<a href="#id47"><span class="problematic" id="id48">*</span></a>args: names of Xvars that aleady exist in the object
lags: int greater than 0, default 1</p>
<blockquote>
<div><p>the number of times to lag each passed variable</p>
</div></blockquote>
<dl class="simple">
<dt>upto: bool, default True</dt><dd><p>whether to add all lags up to the number passed to lags
if you pass 6 to lags and upto is True, lags 1, 2, 3, 4, 5, 6 will all be added
if you pass 6 to lags and upto is False, lag 6 only will be added</p>
</dd>
<dt>sep: str, default ‘_’</dt><dd><p>the separator between each term in arg to create the final variable name
resulting variable names will be like “tlag_1” or “tlag_2” by default</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_logged_terms">
<span class="sig-name descname"><span class="pre">add_logged_terms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">base</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2.718281828459045</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">''</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_logged_terms" title="Permalink to this definition">¶</a></dt>
<dd><p>logs all passed variables (no AR terms)
<a href="#id49"><span class="problematic" id="id50">*</span></a>args: names of Xvars that aleady exist in the object
base: math.e or int greater than 1</p>
<blockquote>
<div><p>the log base</p>
</div></blockquote>
<dl class="simple">
<dt>sep: str, default ‘’</dt><dd><p>the separator between each term in arg to create the final variable name
resulting variable names will be like “log2t” or “lnt” by default</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_other_regressor">
<span class="sig-name descname"><span class="pre">add_other_regressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">called</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">start</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">end</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_other_regressor" title="Permalink to this definition">¶</a></dt>
<dd><p>adds dummy variable that is 1 during the specified time period, 0 otherwise
called: str</p>
<blockquote>
<div><p>what to call the resulting variable</p>
</div></blockquote>
<p>start: str, datetime, or pd.Timestamp object
end: str, datetime, or pd.Timestamp object</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_poly_terms">
<span class="sig-name descname"><span class="pre">add_poly_terms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pwr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'^'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_poly_terms" title="Permalink to this definition">¶</a></dt>
<dd><p>raises all passed variables (no AR terms) to exponential powers (ints only)
<a href="#id51"><span class="problematic" id="id52">*</span></a>args: names of Xvars that aleady exist in the object
pwr: int, default 2</p>
<blockquote>
<div><p>the max power to add to each term in args (2 to this number will be added)</p>
</div></blockquote>
<dl class="simple">
<dt>sep: str, default ‘^’</dt><dd><p>the separator between each term in arg to create the final variable name</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_pt_terms">
<span class="sig-name descname"><span class="pre">add_pt_terms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'box-cox'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sep</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'_'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_pt_terms" title="Permalink to this definition">¶</a></dt>
<dd><p>applies a box-cox or yeo-johnson power transformation to all passed variables (no AR terms)
<a href="#id53"><span class="problematic" id="id54">*</span></a>args: names of Xvars that aleady exist in the object
method: one of {‘box-cox’,’yeo-johnson’}, default ‘box-cox’</p>
<blockquote>
<div><p>the type of transformation
box-cox works for positive values only
yeo-johnson is like a box-cox but can be used with 0s or negatives (<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html</a>)</p>
</div></blockquote>
<dl class="simple">
<dt>sep: str, default ‘’</dt><dd><p>the separator between each term in arg to create the final variable name
resulting variable names will be like “box-cox_t” or “yeo-johnson_t” by default</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_seasonal_regressors">
<span class="sig-name descname"><span class="pre">add_seasonal_regressors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">raw</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sincos</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dummy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_seasonal_regressors" title="Permalink to this definition">¶</a></dt>
<dd><p>adds seasonal regressors to the object
<a href="#id55"><span class="problematic" id="id56">*</span></a>args: each of str type</p>
<blockquote>
<div><p>values that return a series of int type from pandas.dt and pandas.dt.isocalendar()</p>
</div></blockquote>
<dl class="simple">
<dt>raw: bool, default True</dt><dd><p>whether to use the raw integer values</p>
</dd>
<dt>sincos: bool, default False</dt><dd><p>whether to use a sin/cos transformation of the raw integer values (estimates the cycle based on the max observed value)</p>
</dd>
<dt>dummy: bool, default False</dt><dd><p>whether to use dummy variables from the raw int values</p>
</dd>
<dt>drop_first: bool, default False</dt><dd><p>whether to drop the first observed dummy level (saves a degree of freedom when model estimates an intercept)
not relevant when dummy = False</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.add_time_trend">
<span class="sig-name descname"><span class="pre">add_time_trend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">called</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'t'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.add_time_trend" title="Permalink to this definition">¶</a></dt>
<dd><p>adds a time trend from 0 to len(current_dates) + len(future_dates)
called: str, default ‘t’</p>
<blockquote>
<div><p>what to call the resulting variable</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.adf_test">
<span class="sig-name descname"><span class="pre">adf_test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">critical_pval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quiet</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_res</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">,</span> </span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.adf_test" title="Permalink to this definition">¶</a></dt>
<dd><p>tests the stationarity of the y series using augmented dickey fuller
critical_pval: float, default 0.05</p>
<blockquote>
<div><p>the p-value threshold in the statistical test to accept the alternative hypothesis</p>
</div></blockquote>
<dl class="simple">
<dt>quiet: bool, default True</dt><dd><p>if False, prints whether the tests suggests stationary or non-stationary data</p>
</dd>
<dt>full_res: bool, default False</dt><dd><p>if True, returns a dictionary with the pvalue, evaluated statistic, and other statistical information (returns what the adfuller() function from statsmodels does)
if False, returns a bool that matches whether the test indicates stationarity</p>
</dd>
<dt>train_only: bool, default False</dt><dd><p>if True, will exclude the test set from the test (a measure added to avoid leakage)</p>
</dd>
</dl>
<p><a href="#id57"><span class="problematic" id="id58">**</span></a>kwargs passed to adfuller() function from statsmodels</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.all_feature_info_to_excel">
<span class="sig-name descname"><span class="pre">all_feature_info_to_excel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">excel_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'feature_info.xlsx'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.all_feature_info_to_excel" title="Permalink to this definition">¶</a></dt>
<dd><p>saves all feature importance and summary stats to excel
each model where such info is available for gets its own tab
be sure to call save_summary_stats() and save_feature_importance() before using this function
out_path: str, default ‘./’</p>
<blockquote>
<div><p>the path to export to</p>
</div></blockquote>
<dl class="simple">
<dt>excel_name: str, default ‘feature_info.xlsx’</dt><dd><p>the name of the resulting excel file</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.all_validation_grids_to_excel">
<span class="sig-name descname"><span class="pre">all_validation_grids_to_excel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">out_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">excel_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'validation_grids.xlsx'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sort_by_metric_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ascending</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.all_validation_grids_to_excel" title="Permalink to this definition">¶</a></dt>
<dd><p>saves all validation grids to excel
each model where such info is available for gets its own tab
out_path: str, default ‘./’</p>
<blockquote>
<div><p>the path to export to</p>
</div></blockquote>
<dl class="simple">
<dt>excel_name: str, default ‘feature_info.xlsx’</dt><dd><p>the name of the resulting excel file</p>
</dd>
</dl>
<p>sort_by_metric_value: bool, default False
ascending: bool, default True</p>
<blockquote>
<div><p>whether to sort least-to-greatest
ignored if sort_by_metric_value is False</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.auto_forecast">
<span class="sig-name descname"><span class="pre">auto_forecast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">call_me</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamic_testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.auto_forecast" title="Permalink to this definition">¶</a></dt>
<dd><p>auto forecast with the best parameters indicated from the tuning process
see manual_forecast() docstring</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.diff">
<span class="sig-name descname"><span class="pre">diff</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.diff" title="Permalink to this definition">¶</a></dt>
<dd><p>differences the y attribute, as well as all regressor values stored in current_xreg and future_xreg
call this after adding all desired ar terms and those terms will be differenced too
if you add ar terms after differencing, an error will be raised
i: one of {0,1,2}, default 1</p>
<blockquote>
<div><p>the number of differences to take</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.drop_Xvars">
<span class="sig-name descname"><span class="pre">drop_Xvars</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.drop_Xvars" title="Permalink to this definition">¶</a></dt>
<dd><p>drops regressors
<a href="#id59"><span class="problematic" id="id60">*</span></a>args are names of regressors to drop</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.drop_regressors">
<span class="sig-name descname"><span class="pre">drop_regressors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.drop_regressors" title="Permalink to this definition">¶</a></dt>
<dd><p>drops regressors
<a href="#id61"><span class="problematic" id="id62">*</span></a>args are names of regressors to drop</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.export">
<span class="sig-name descname"><span class="pre">export</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dfs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['all_fcsts',</span> <span class="pre">'model_summaries',</span> <span class="pre">'best_fcst',</span> <span class="pre">'test_set_predictions',</span> <span class="pre">'lvl_test_set_predictions',</span> <span class="pre">'lvl_fcsts']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">models</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">best_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">determine_best_by</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'TestSetRMSE'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_excel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">excel_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'results.xlsx'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">pandas.core.frame.DataFrame</span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.export" title="Permalink to this definition">¶</a></dt>
<dd><p>exports 1-all of 5 pandas dataframes, can write to excel with each dataframe on a separate sheet
will return either a dictionary with dataframes as values (df str arguments as keys) or a single dataframe if only one df is specified
dfs: list-like or str, default [‘all_fcsts’,’model_summaries’,’best_fcst’,’test_set_predictions’,’lvl_fcsts’]</p>
<blockquote>
<div><p>a list or name of the specific dataframe(s) you want returned and/or written to excel
must be one of or multiple of default</p>
</div></blockquote>
<dl class="simple">
<dt>models: list-like or str, default ‘all’</dt><dd><p>the models to write information for
can start with “<a href="#id85"><span class="problematic" id="id86">top_</span></a>” and the metric specified in <cite>determine_best_by</cite> will be used to order the models appropriately</p>
</dd>
<dt>best_model: str, default ‘auto’</dt><dd><p>the name of the best model, if “auto”, will determine this by the metric in determine_best_by
if not “auto”, must match a model nickname of an already-evaluated model</p>
</dd>
</dl>
<p>determine_best_by: one of _determine_best_by_, default ‘TestSetRMSE’
to_excel: bool, default False</p>
<blockquote>
<div><p>whether to save to excel</p>
</div></blockquote>
<dl class="simple">
<dt>out_path: str, default ‘./’</dt><dd><p>the path to save the excel file to (ignored when <cite>to_excel=False</cite>)</p>
</dd>
<dt>excel_name: str, default ‘results.xlsx’</dt><dd><p>the name to call the excel file (ignored when <cite>to_excel=False</cite>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.export_Xvars_df">
<span class="sig-name descname"><span class="pre">export_Xvars_df</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dropna</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.export_Xvars_df" title="Permalink to this definition">¶</a></dt>
<dd><p>returns a pandas dataframe with all utilized regressors and values
dropna: bool, default False</p>
<blockquote>
<div><p>whether to drop null values from the resulting dataframe</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.export_feature_importance">
<span class="sig-name descname"><span class="pre">export_feature_importance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">pandas.core.frame.DataFrame</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.export_feature_importance" title="Permalink to this definition">¶</a></dt>
<dd><p>exports the feature importance from a model
raises an error if you never saved the model’s feature importance
model: str</p>
<blockquote>
<div><p>the name of them model to export for, matches what was passed to call_me when calling the forecast (default is estimator name)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.export_fitted_vals">
<span class="sig-name descname"><span class="pre">export_fitted_vals</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.export_fitted_vals" title="Permalink to this definition">¶</a></dt>
<dd><p>exports a single dataframe with fitted values and actuals
model: str</p>
<blockquote>
<div><p>the model nickname (must exist in history.keys())</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.export_forecasts_with_cis">
<span class="sig-name descname"><span class="pre">export_forecasts_with_cis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.export_forecasts_with_cis" title="Permalink to this definition">¶</a></dt>
<dd><p>exports a single dataframe with forecasts and upper and lower forecast bounds
model: str</p>
<blockquote>
<div><p>the model nickname (must exist in history.keys())</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.export_summary_stats">
<span class="sig-name descname"><span class="pre">export_summary_stats</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">pandas.core.frame.DataFrame</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.export_summary_stats" title="Permalink to this definition">¶</a></dt>
<dd><p>exports the summary stats from a model
raises an error if you never saved the model’s summary stats
model: str</p>
<blockquote>
<div><p>the name of them model to export for, matches what was passed to call_me when calling the forecast (default is estimator name)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.export_test_set_preds_with_cis">
<span class="sig-name descname"><span class="pre">export_test_set_preds_with_cis</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.export_test_set_preds_with_cis" title="Permalink to this definition">¶</a></dt>
<dd><p>exports a single dataframe with test-set predictions, actuals, and upper and lower prediction bounds
model: str</p>
<blockquote>
<div><p>the model nickname (must exist in history.keys())</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.export_validation_grid">
<span class="sig-name descname"><span class="pre">export_validation_grid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">pandas.core.frame.DataFrame</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.export_validation_grid" title="Permalink to this definition">¶</a></dt>
<dd><p>exports the validation from a model
raises an error if you never tuned the model
model: str</p>
<blockquote>
<div><p>the name of them model to export for, matches what was passed to call_me when calling the forecast (default is estimator name)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.fillna_y">
<span class="sig-name descname"><span class="pre">fillna_y</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">how</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'ffill'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.fillna_y" title="Permalink to this definition">¶</a></dt>
<dd><p>fills null values in the y attribute
how: {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, ‘midpoint’}</p>
<blockquote>
<div><p>midpoint is unique to this library and only works if there is not more than two missing values sequentially
all other possible arguments are from pandas.DataFrame.fillna() method and will do the same</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.generate_future_dates">
<span class="sig-name descname"><span class="pre">generate_future_dates</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.generate_future_dates" title="Permalink to this definition">¶</a></dt>
<dd><p>generates a certain amount of future dates based on an inferred frequency
n: int</p>
<blockquote>
<div><p>number of future dates to produce
this will also be the forecast length</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.get_freq">
<span class="sig-name descname"><span class="pre">get_freq</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">str</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.get_freq" title="Permalink to this definition">¶</a></dt>
<dd><p>returns the pandas inferred date frequency</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.get_funcs">
<span class="sig-name descname"><span class="pre">get_funcs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">which</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.get_funcs" title="Permalink to this definition">¶</a></dt>
<dd><p>returns a group of functions based on what’s passed to which
which: str, one of {‘adder’,’exporter’,’setter’,’plotter’,’getter’}</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.get_regressor_names">
<span class="sig-name descname"><span class="pre">get_regressor_names</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.get_regressor_names" title="Permalink to this definition">¶</a></dt>
<dd><p>returns a lit of regressor names stored in the object</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.infer_freq">
<span class="sig-name descname"><span class="pre">infer_freq</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.infer_freq" title="Permalink to this definition">¶</a></dt>
<dd><p>uses pandas library to infer frequency of loaded dates</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.ingest_Xvars_df">
<span class="sig-name descname"><span class="pre">ingest_Xvars_df</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">df</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">date_col</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'Date'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">drop_first</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_future_dates</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.ingest_Xvars_df" title="Permalink to this definition">¶</a></dt>
<dd><p>ingest a dataframe of regressors with names (don’t start anything with AR!!!)
all non-numeric values will be dummied
df: pandas.DataFrame
date_col: str, default ‘Date’</p>
<blockquote>
<div><p>the name of the date column in the dataframe (use named index only if passing this column as an index)</p>
</div></blockquote>
<dl class="simple">
<dt>drop_first: bool, default False</dt><dd><p>whether to drop the first observation of any dummied variables, irrelevant if passing all numeric values</p>
</dd>
<dt>use_future_dates: bool, default False</dt><dd><p>whether to use the future dates in the dataframe as the future_dates attribute in the object
if False, the dataframe must have at least the same number of observations as len(future_dates)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.ingest_grid">
<span class="sig-name descname"><span class="pre">ingest_grid</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grid</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.ingest_grid" title="Permalink to this definition">¶</a></dt>
<dd><p>ingests a grid to tune the estimator
grid: dict or str</p>
<blockquote>
<div><p>if dict, must be a user-created grid
if str, must match the name of a dict grid stored in Grids.py</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.integrate">
<span class="sig-name descname"><span class="pre">integrate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">critical_pval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.05</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_integration</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.integrate" title="Permalink to this definition">¶</a></dt>
<dd><p>differences the series 0, 1, or 2 times based on ADF test
critical_pval: float, default 0.05</p>
<blockquote>
<div><p>the p-value threshold in the statistical test to accept the alternative hypothesis</p>
</div></blockquote>
<dl class="simple">
<dt>train_only: bool, default False</dt><dd><p>if True, will exclude the test set from the test (a measure added to avoid leakage)</p>
</dd>
<dt>max_integration: int, one of {1,2}, default 2</dt><dd><p>if 1, will only difference data up to one time even if the results of the test indicate two integrations
if 2, behaves how you would expect</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.keep_smaller_history">
<span class="sig-name descname"><span class="pre">keep_smaller_history</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.keep_smaller_history" title="Permalink to this definition">¶</a></dt>
<dd><p>cuts the amount of observations in the object (trims the current_dates and current_xreg attributes as well)
n: int, str in ‘%Y-%m-%d’ format, or datetime object</p>
<blockquote>
<div><p>if int, the number of observations to keep
otherwise, the last observation to keep</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.limit_grid_size">
<span class="sig-name descname"><span class="pre">limit_grid_size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.limit_grid_size" title="Permalink to this definition">¶</a></dt>
<dd><p>makes a grid smaller randomly
n: int or float</p>
<blockquote>
<div><p>if int, randomly selects that many parameter combinations
if float, must be less than 1 and greater 0, randomly selects that percentage of parameter combinations</p>
</div></blockquote>
<dl class="simple">
<dt>random_seed: int, optional</dt><dd><p>set a seed to make results consistent</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.manual_forecast">
<span class="sig-name descname"><span class="pre">manual_forecast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">call_me</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamic_testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.manual_forecast" title="Permalink to this definition">¶</a></dt>
<dd><p>manually forecasts with the hyperparameters, Xvars, and normalizer selection passed as keywoords
call_me: str, optional</p>
<blockquote>
<div><p>what to call the model when storing it in the object’s history dictionary
if not specified, the model’s nickname will be assigned the estimator value (‘mlp’ will be ‘mlp’, etc.)
duplicated names will be overwritten with the most recently called model</p>
</div></blockquote>
<dl class="simple">
<dt>dynamic_testing: bool, default True</dt><dd><p>whether to dynamically test the forecast (meaning AR terms will be propogated with predicted values)
setting this to False means faster performance, but gives a less-good indication of how well the forecast will perform out x amount of periods
when False, test-set metrics effectively become an average of one-step forecasts</p>
</dd>
</dl>
<p><a href="#id63"><span class="problematic" id="id64">**</span></a>kwargs are passed to the _forecast_{estimator}() method and can include such parameters as Xvars, normalizer, cap, and floor, in addition to any given model’s specific hyperparameters
<a href="#id65"><span class="problematic" id="id66">**</span></a>kwargs include for sklearn and lstm models:</p>
<blockquote>
<div><dl class="simple">
<dt>normalizer: one of {_normalizer_}, default ‘minmax’</dt><dd><p>if not None, normalizer applied to training data only to not leak</p>
</dd>
<dt>Xvars: list where all elements are in current_xreg keys, ‘all’, or None</dt><dd><p>if None and Xvars are required, None becomes equivalent to ‘all’</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.order_fcsts">
<span class="sig-name descname"><span class="pre">order_fcsts</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">models</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">determine_best_by</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'TestSetRMSE'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">list</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.order_fcsts" title="Permalink to this definition">¶</a></dt>
<dd><p>returns a list of estiamated forecasts from best-to-worst
models: list-like</p>
<blockquote>
<div><p>each element must match an element in _estimators_ (except “combo”, which cannot be tuned)</p>
</div></blockquote>
<p>determine_best_by: one of _determine_best_by_</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.plot">
<span class="sig-name descname"><span class="pre">plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">models</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order_by</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">print_attr</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_png</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">png_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'plot.png'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ci</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.plot" title="Permalink to this definition">¶</a></dt>
<dd><p>plots all forecasts with the actuals, or just actuals if no forecasts available
models: list-like, str, or None; default ‘all’</p>
<blockquote>
<div><p>the forecated models to plot
can start with “<a href="#id87"><span class="problematic" id="id88">top_</span></a>” and the metric specified in order_by will be used to order the models appropriately
if None or models/order_by combo invalid, will plot only actual values</p>
</div></blockquote>
<p>order_by: one of _determine_best_by_, default None
level: bool, default False</p>
<blockquote>
<div><p>if True, will always plot level forecasts
if False, will plot the forecasts at whatever level they were called on
if False and there are a mix of models passed with different integrations, will default to True</p>
</div></blockquote>
<dl class="simple">
<dt>print_attr: list-like, default []</dt><dd><p>attributes from history dict to print to console
if the attribute doesn’t exist for a passed model, will not raise error, will just skip that element</p>
</dd>
<dt>to_png: bool, default False</dt><dd><p>whether to save the resulting image to a png file</p>
</dd>
<dt>out_path: str, default ‘./’</dt><dd><p>the path to save the png file to (ignored when <cite>to_png=False</cite>)</p>
</dd>
<dt>png_name: str, default ‘./plot.png’</dt><dd><p>the name of the resulting png image (ignored when <cite>to_png=False</cite>)</p>
</dd>
<dt>ci: bool, default False</dt><dd><p>whether to display the confidence intervals
default is 100 boostrapped samples and a 95% confidence interval
change defaults by calling <cite>set_cilevel()</cite> and <cite>set_bootstrapped_samples()</cite> before forecasting
ignored when level = False</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.plot_acf">
<span class="sig-name descname"><span class="pre">plot_acf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">diffy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">&lt;module</span> <span class="pre">‘matplotlib.pyplot’</span> <span class="pre">from</span> <span class="pre">‘C:\Users\michaelkeith\Anaconda3\lib\site-packages\matplotlib\pyplot.py’&gt;</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.plot_acf" title="Permalink to this definition">¶</a></dt>
<dd><p>plots an autocorrelation function of the y values
diffy: one of {True,False,0,1,2}, default False</p>
<blockquote>
<div><p>whether to difference the data and how many times before passing the values to the function
If False or 0, does not difference
If True or 1, differences 1 time
If 2, differences 2 times</p>
</div></blockquote>
<dl class="simple">
<dt>train_only: bool, default False</dt><dd><p>if True, will exclude the test set from the test (a measure added to avoid leakage)</p>
</dd>
</dl>
<p><a href="#id67"><span class="problematic" id="id68">**</span></a>kwargs passed to plot_acf() function from statsmodels</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.plot_fitted">
<span class="sig-name descname"><span class="pre">plot_fitted</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">models</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order_by</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_png</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">png_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./plot.png'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.plot_fitted" title="Permalink to this definition">¶</a></dt>
<dd><p>plots all fitted values with the actuals
models: list-like or str, default ‘all’</p>
<blockquote>
<div><p>the forecated models to plot
can start with “<a href="#id89"><span class="problematic" id="id90">top_</span></a>” and the metric specified in order_by will be used to order the models appropriately</p>
</div></blockquote>
<p>order_by: one of _determine_best_by_, default None
to_png: bool, default False</p>
<blockquote>
<div><p>whether to save the resulting image to a png file</p>
</div></blockquote>
<dl class="simple">
<dt>out_path: str, default ‘./’</dt><dd><p>the path to save the png file to (ignored when <cite>to_png=False</cite>)</p>
</dd>
<dt>png_name: str, default ‘./plot.png’</dt><dd><p>the name of the resulting png image (ignored when <cite>to_png=False</cite>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.plot_pacf">
<span class="sig-name descname"><span class="pre">plot_pacf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">diffy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">&lt;module</span> <span class="pre">‘matplotlib.pyplot’</span> <span class="pre">from</span> <span class="pre">‘C:\Users\michaelkeith\Anaconda3\lib\site-packages\matplotlib\pyplot.py’&gt;</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.plot_pacf" title="Permalink to this definition">¶</a></dt>
<dd><p>plots a partial autocorrelation function of the y values
diffy: one of {True,False,0,1,2}, default False</p>
<blockquote>
<div><p>whether to difference the data and how many times before passing the values to the function
If False or 0, does not difference
If True or 1, differences 1 time
If 2, differences 2 times</p>
</div></blockquote>
<dl class="simple">
<dt>train_only: bool, default False</dt><dd><p>if True, will exclude the test set from the test (a measure added to avoid leakage)</p>
</dd>
</dl>
<p><a href="#id69"><span class="problematic" id="id70">**</span></a>kwargs passed to plot_pacf() function from statsmodels</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.plot_periodogram">
<span class="sig-name descname"><span class="pre">plot_periodogram</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">diffy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.plot_periodogram" title="Permalink to this definition">¶</a></dt>
<dd><p>plots a periodogram of the y values (comes from scipy.signal)
diffy: one of {True,False,0,1,2}, default False</p>
<blockquote>
<div><p>whether to difference the data and how many times before passing the values to the function
If False or 0, does not difference
If True or 1, differences 1 time
If 2, differences 2 times</p>
</div></blockquote>
<dl class="simple">
<dt>train_only: bool, default False</dt><dd><p>if True, will exclude the test set from the test (a measure added to avoid leakage)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.plot_test_set">
<span class="sig-name descname"><span class="pre">plot_test_set</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">models</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'all'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">order_by</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">level</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_png</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">png_name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'./plot.png'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ci</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.plot_test_set" title="Permalink to this definition">¶</a></dt>
<dd><p>plots all test-set predictions with the actuals
models: list-like or str, default ‘all’</p>
<blockquote>
<div><p>the forecated models to plot
can start with “<a href="#id91"><span class="problematic" id="id92">top_</span></a>” and the metric specified in order_by will be used to order the models appropriately</p>
</div></blockquote>
<p>order_by: one of _determine_best_by_, default None
include_train: bool or int, default True</p>
<blockquote>
<div><p>use to zoom into training results
if True, plots the test results with the entire history in y
if False, matches y history to test results and only plots this
if int, plots that length of y to match to test results</p>
</div></blockquote>
<dl class="simple">
<dt>level: bool, default False</dt><dd><p>if True, will always plot level forecasts
if False, will plot the forecasts at whatever level they were called on
if False and there are a mix of models passed with different integrations, will default to True</p>
</dd>
<dt>to_png: bool, default False</dt><dd><p>whether to save the resulting image to a png file</p>
</dd>
<dt>out_path: str, default ‘./’</dt><dd><p>the path to save the png file to (ignored when <cite>to_png=False</cite>)</p>
</dd>
<dt>png_name: str, default ‘./plot.png’</dt><dd><p>the name of the resulting png image (ignored when <cite>to_png=False</cite>)</p>
</dd>
<dt>ci: bool, default False</dt><dd><p>whether to display the confidence intervals
default is 100 boostrapped samples and a 95% confidence interval
change defaults by calling <cite>set_cilevel()</cite> and <cite>set_bootstrapped_samples()</cite> before forecasting
ignored when level = False</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.pop">
<span class="sig-name descname"><span class="pre">pop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.pop" title="Permalink to this definition">¶</a></dt>
<dd><p>deletes evaluated forecasts from the history dictionary
<a href="#id71"><span class="problematic" id="id72">*</span></a>args names of models matching what was passed to call_me (default for call_me in a given model is the same as the estimator name)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.pop_using_criterion">
<span class="sig-name descname"><span class="pre">pop_using_criterion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluated_as</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delete_all</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.pop_using_criterion" title="Permalink to this definition">¶</a></dt>
<dd><p>deletes all forecasts from history that meet a given criterion
metric: str, one of _determine_best_by_ + [‘AnyPrediction’,’AnyLevelPrediction’]
evaluated_as: str, one of {“&lt;”,”&lt;=”,”&gt;”,”&gt;=”,”==”}
threshold: float
delete_all: bool, default True</p>
<blockquote>
<div><p>if the passed criterion deletes all forecasts, whether to actually delete all forecasts
if False and all forecasts meet criterion, will keep them all</p>
</div></blockquote>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="o">.</span><span class="n">pop_using_criterion</span><span class="p">(</span><span class="s1">&#39;LevelTestSetMAPE&#39;</span><span class="p">,</span><span class="s1">&#39;&gt;&#39;</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="o">.</span><span class="n">pop_using_criterion</span><span class="p">(</span><span class="s1">&#39;AnyPrediction&#39;</span><span class="p">,</span><span class="s1">&#39;&lt;&#39;</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="n">delete_all</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>drops all regressors and reverts object to original (level) state when initiated</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.save_feature_importance">
<span class="sig-name descname"><span class="pre">save_feature_importance</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.save_feature_importance" title="Permalink to this definition">¶</a></dt>
<dd><p>save feature info for models that offer it
will not raise errors if not available</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.save_summary_stats">
<span class="sig-name descname"><span class="pre">save_summary_stats</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.save_summary_stats" title="Permalink to this definition">¶</a></dt>
<dd><p>save summary stats for models that offer it
will not raise errors if not available</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.seasonal_decompose">
<span class="sig-name descname"><span class="pre">seasonal_decompose</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">diffy</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_only</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.seasonal_decompose" title="Permalink to this definition">¶</a></dt>
<dd><p>plots a signal/seasonal decomposition of the y values
diffy: one of {True,False,0,1,2}, default False</p>
<blockquote>
<div><p>whether to difference the data and how many times before passing the values to the function
If False or 0, does not difference
If True or 1, differences 1 time
If 2, differences 2 times</p>
</div></blockquote>
<dl class="simple">
<dt>train_only: bool, default False</dt><dd><p>if True, will exclude the test set from the test (a measure added to avoid leakage)</p>
</dd>
</dl>
<p><a href="#id73"><span class="problematic" id="id74">**</span></a>kwargs passed to seasonal_decompose() function from statsmodels</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.set_bootstrap_samples">
<span class="sig-name descname"><span class="pre">set_bootstrap_samples</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.set_bootstrap_samples" title="Permalink to this definition">¶</a></dt>
<dd><p>sets the number of bootstrap samples to set confidence intervals for each model (default is 100)
n: float greater than or equal to 30</p>
<blockquote>
<div><p>30 because you need around there to satisfy central limit theorem
the lower this number, the faster the performance, but the less sure of the outcome you can be</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.set_cilevel">
<span class="sig-name descname"><span class="pre">set_cilevel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.set_cilevel" title="Permalink to this definition">¶</a></dt>
<dd><p>sets the level for the resulting confidence intervals (95% default)
n: float greater than 0 and less than 1</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.set_estimator">
<span class="sig-name descname"><span class="pre">set_estimator</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">estimator</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.set_estimator" title="Permalink to this definition">¶</a></dt>
<dd><p>sets the estimator to forecast with
estimator: one of _estimators_</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.set_last_future_date">
<span class="sig-name descname"><span class="pre">set_last_future_date</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">date</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.set_last_future_date" title="Permalink to this definition">¶</a></dt>
<dd><p>generates future dates that ends on the passed date
date: datetime.datetime, pandas.Timestamp, or str (‘%Y-%m-%d’ format)</p>
<blockquote>
<div><p>the date to end on
the number of future generated dates will be used as the forecast length</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.set_test_length">
<span class="sig-name descname"><span class="pre">set_test_length</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.set_test_length" title="Permalink to this definition">¶</a></dt>
<dd><p>set the length of the test set (no fractional splits)
n: int, default 1</p>
<blockquote>
<div><p>the length of the resulting test set</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.set_validation_length">
<span class="sig-name descname"><span class="pre">set_validation_length</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.set_validation_length" title="Permalink to this definition">¶</a></dt>
<dd><p>set the length of the validation set (no fractional splits)
n: int, default 1</p>
<blockquote>
<div><p>the length of the resulting validation set</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.set_validation_metric">
<span class="sig-name descname"><span class="pre">set_validation_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'rmse'</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.set_validation_metric" title="Permalink to this definition">¶</a></dt>
<dd><p>sets the metric that will be used to tune all subsequent models
not a good idea to change this if you are planning to combo model as weird things could happen
metric: one of _metrics_, default ‘rmse’</p>
<blockquote>
<div><p>the metric to optimize the models on using the validation set</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.tune">
<span class="sig-name descname"><span class="pre">tune</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dynamic_tuning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.tune" title="Permalink to this definition">¶</a></dt>
<dd><p>tunes the specified estimator using an ingested grid (ingests a grid from Grids.py with same name as the estimator by default)
any parameters you can pass as <a href="#id75"><span class="problematic" id="id76">**</span></a>kwargs to manual_forecast() can be tuned with this process
dynamic_tuning: bool, default False</p>
<blockquote>
<div><p>whether to dynamically tune the forecast (meaning AR terms will be propogated with predicted values)
setting this to False means faster performance, but gives a less-good indication of how well the forecast will perform out x amount of periods
when False, metrics effectively become an average of one-step forecasts</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.tune_test_forecast">
<span class="sig-name descname"><span class="pre">tune_test_forecast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">models</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamic_tuning</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dynamic_testing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">summary_stats</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_importance</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.tune_test_forecast" title="Permalink to this definition">¶</a></dt>
<dd><p>iterates through a list of models, tunes them using grids in Grids.py, forecasts them, and can save feature information
models: list-like</p>
<blockquote>
<div><p>each element must match an element in _estimators_ (except “combo”, which cannot be tuned)</p>
</div></blockquote>
<dl class="simple">
<dt>dynamic_tuning: bool, default False</dt><dd><p>whether to dynamically tune the forecast (meaning AR terms will be propogated with predicted values)
setting this to False means faster performance, but gives a less-good indication of how well the forecast will perform out x amount of periods
when False, metrics effectively become an average of one-step forecasts</p>
</dd>
<dt>dynamic_testing: bool, default True</dt><dd><p>whether to dynamically test the forecast (meaning AR terms will be propogated with predicted values)
setting this to False means faster performance, but gives a less-good indication of how well the forecast will perform out x amount of periods
when False, test-set metrics effectively become an average of one-step forecasts</p>
</dd>
<dt>summary_stats: bool, default False</dt><dd><p>whether to save summary stats for the models that offer those</p>
</dd>
<dt>feature_importance: bool, default False</dt><dd><p>whether to save permutation feature importance information for the models that offer those</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.typ_set">
<span class="sig-name descname"><span class="pre">typ_set</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.typ_set" title="Permalink to this definition">¶</a></dt>
<dd><p>converts all objects in y, current_dates, future_dates, current_xreg, and future_xreg to appropriate types if possible</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.undiff">
<span class="sig-name descname"><span class="pre">undiff</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">suppress_error</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.undiff" title="Permalink to this definition">¶</a></dt>
<dd><p>undifferences y to original level and drops all regressors (such as AR terms)
suppress_error: bool, default False</p>
<blockquote>
<div><p>whether to suppress an error that gets raised if the series was never differenced</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="scalecast.Forecaster.Forecaster.validate_regressor_names">
<span class="sig-name descname"><span class="pre">validate_regressor_names</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; <span class="pre">None</span><a class="headerlink" href="#scalecast.Forecaster.Forecaster.validate_regressor_names" title="Permalink to this definition">¶</a></dt>
<dd><p>validates that all regressor names exist in both current_xregs and future_xregs</p>
</dd></dl>

</dd></dl>

</section>


      </div>
      <div class="bottomnav" role="navigation" aria-label="bottom navigation">
      
        <p>
        «&#160;&#160;<a href="examples/LSTM.html">LSTM Example</a>
        &#160;&#160;::&#160;&#160;
        <a class="uplink" href="../index.html">Contents</a>
        &#160;&#160;::&#160;&#160;
        <a href="ForecasterGlobals.html">Forecaster Object Globals</a>&#160;&#160;»
        </p>

      </div>

    <div class="footer" role="contentinfo">
        &#169; Copyright 2022, Michael Keith.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.0.1.
    </div>
  </body>
</html>